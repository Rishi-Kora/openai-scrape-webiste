{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc7a046-7550-40ad-9fef-56b22ae9a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "from searchwebsite import Website\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e6a9800-7146-4719-abc7-0eb37f6c3ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8316fced-13be-4fc1-86e9-9129ab6b7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c67106d-b51f-4a81-a354-ab6593a6c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(url: str):\n",
    "    # instantiate your Website loader\n",
    "    website = Website(url)\n",
    "# print(website.title)\n",
    "# print(website.text)\n",
    "# website.links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca975d8d-71f5-414b-91d6-bce0841bef24",
   "metadata": {},
   "source": [
    "# sending information to model first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54bbc68b-d276-4cc6-944e-02213fcee277",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7615a5ff-7c37-4096-bda5-c7f28f042354",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            \"Here’s a list of URLs I’d like you to analyze:\\n\\n\"\n",
    "            f\"{website.links}\\n\\n\"\n",
    "            \"Can you please:\\n\"\n",
    "            \"1. Use all the links that will be useful for creating a profession resume\\n\"\n",
    "            \"2. Extract domain names.\\n\"\n",
    "            \"3. Summarize what kind of content lives at each URL (e.g. blog post, homepage, contact page).\"\n",
    "        )}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Print out the assistant’s reply\n",
    "ass_response = response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b14d116-c08a-444f-8544-a8646c7d7b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here’s an organized breakdown of your URLs:\\n\\n1. Links most useful when building a professional résumé/profile  \\n   • /education  \\n   • /Intellectual_Portfolio  \\n   • /AI_hub  \\n   • /contact  \\n   • https://www.linkedin.com/in/premkora/  \\n   • https://x.com/premkumarkora  \\n\\n2. Domain names extracted  \\n   • (relative URLs): your personal site’s domain (e.g. “yourname.com”)  \\n   • medium.com  \\n   • linkedin.com  \\n   • x.com  \\n\\n3. Brief summary of each URL’s content\\n\\n• #thememaincontent  \\n  – Anchor/skip link to the main content area on a page.  \\n  – Not a standalone page.\\n\\n• /  \\n  – Homepage of your personal site.  \\n  – Likely overview of who you are, key achievements, navigation to other sections.\\n\\n• /AI_hub  \\n  – “AI Hub” section/page on your site.  \\n  – Likely showcases AI projects, tools, articles or a portfolio of AI-related work.\\n\\n• /Intellectual_Portfolio  \\n  – Dedicated portfolio of publications, patents, whitepapers or research.  \\n  – Highlights your intellectual contributions and expertise.\\n\\n• /education  \\n  – Education page on your site.  \\n  – Lists degrees, certifications, training programs and perhaps coursework.\\n\\n• /contact  \\n  – Contact page on your site.  \\n  – Provides email address, contact form, maybe phone number or location.\\n\\n• https://medium.com/@consultkora/specialized-ai-intelligence-vertical-ai-agents-749ad5ca4106  \\n  – Blog post on Medium: “Specialized AI Intelligence / Vertical AI Agents.”  \\n  – Explores domain-specific AI agents and their applications.\\n\\n• https://medium.com/@consultkora/fine-tuning-foundational-models-a-guide-to-customizing-ai-for-specific-needs-295c8a6222e6  \\n  – Medium article: “Fine-Tuning Foundational Models.”  \\n  – Guide on customizing large AI models for niche tasks.\\n\\n• https://medium.com/@consultkora/evaluating-machine-learning-and-deep-learning-models-5a5b17234488  \\n  – Medium article: “Evaluating ML and Deep Learning Models.”  \\n  – Covers metrics, validation strategies and performance evaluation.\\n\\n• https://medium.com/@consultkora/streaming-large-language-models-f3c59d51a9f0  \\n  – Medium article: “Streaming Large Language Models.”  \\n  – Discusses serving LLMs in real-time, architecture and trade-offs.\\n\\n• https://medium.com/@consultkora/bias-and-variance-explained-c1468999b42f  \\n  – Medium article: “Bias and Variance Explained.”  \\n  – Introduction to the bias-variance trade-off in ML.\\n\\n• https://medium.com/@consultkora/data-lineage-understanding-its-role-in-modern-data-management-a50822544c76  \\n  – Medium article: “Data Lineage in Modern Data Management.”  \\n  – Importance of tracking data origin, transformations and usage.\\n\\n• https://medium.com/@consultkora/why-and-when-to-use-discriminative-vs-generative-models-d3f28e254c3e  \\n  – Medium article: “Discriminative vs Generative Models.”  \\n  – Compares the two classes of models, use-cases and pros/cons.\\n\\n• https://medium.com/@consultkora/difference-between-an-ml-algorithm-and-an-ml-model-31f9f0a76c51  \\n  – Medium article: “ML Algorithm vs ML Model.”  \\n  – Clarifies the distinction and how each is used in practice.\\n\\n• javascript:;  \\n  – Placeholder or no-op link in HTML/JS.  \\n  – Not a real resource.\\n\\n• https://www.linkedin.com/in/premkora/  \\n  – LinkedIn profile page.  \\n  – Professional summary, work experience, education, skills, endorsements.\\n\\n• https://x.com/premkumarkora  \\n  – X (formerly Twitter) profile.  \\n  – Social feed—thought leadership posts, announcements, professional updates.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ass_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa188f5a-9a09-4092-aa0c-ec9ee0732a58",
   "metadata": {},
   "source": [
    "# A system prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc7849e-af75-4df7-b46f-ad31afe2dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provide a resume, look for infomation from other links provided \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6b118-3d9e-4599-8a5b-57cca49c46ff",
   "metadata": {},
   "source": [
    "# User Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714b91a1-494a-4e76-b885-96cd3174ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please create a professional resume pass ATS in markdown. \\n\\n\"\n",
    "user_prompt += website.text\n",
    "user_prompt += ass_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b574e5-872b-4d50-9cce-610e888e280b",
   "metadata": {},
   "source": [
    "# sending information to model second time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04bda6b0-defc-4a94-b60f-0ea8f95bd0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# PremKumar Kora  \n",
       "Data Scientist & AI Architect  \n",
       "\n",
       "Email: premkora@example.com • LinkedIn: https://www.linkedin.com/in/premkora/ • X: https://x.com/premkumarkora • Website: yourname.com  \n",
       "\n",
       "---\n",
       "\n",
       "## Professional Summary\n",
       "Seasoned Data Scientist & AI Architect with 25+ years in software technology and artificial intelligence. Specializes in Generative AI, Large Language Models (LLMs), prompt engineering, NLP, predictive analytics, and cloud-based AI deployments. Proven track record designing and delivering enterprise-scale AI solutions, LLMOps frameworks, real-time data pipelines, and automated decision-making systems. Published author and inventor with a passion for mentoring the next generation of AI professionals and driving community-focused humanitarian initiatives.\n",
       "\n",
       "---\n",
       "\n",
       "## Core Competencies\n",
       "• Generative AI & LLMOps  \n",
       "• AI Architecture & System Design  \n",
       "• Machine Learning & Deep Learning  \n",
       "• Natural Language Processing (NLP)  \n",
       "• Prompt Engineering & Transformer Models  \n",
       "• Predictive Analytics & Model Evaluation  \n",
       "• Real-Time Data Pipelines  \n",
       "• Cloud AI Deployment (AWS, Azure, GCP)  \n",
       "• AI Automation & MLOps  \n",
       "• Technical Leadership & Mentoring  \n",
       "\n",
       "---\n",
       "\n",
       "## Professional Experience\n",
       "\n",
       "**Senior Data Scientist & GenAI Architect (Independent Consultant)**  \n",
       "2000 – Present  \n",
       "- Architected and delivered end-to-end AI solutions across finance, healthcare, manufacturing and retail.  \n",
       "- Designed LLMOps frameworks for fine-tuning, deployment and monitoring of large language models.  \n",
       "- Built scalable data ingestion and processing pipelines enabling real-time analytics and automated decision systems.  \n",
       "- Led cross-functional teams to integrate GenAI capabilities into CRM, ERP and custom enterprise applications.  \n",
       "- Authored technical whitepapers and conducted workshops on prompt engineering, model bias mitigation and performance tuning.\n",
       "\n",
       "---\n",
       "\n",
       "## Patents & Intellectual Property\n",
       "- 2+ Patents granted in AI-driven data analytics and model optimization (details available upon request).  \n",
       "\n",
       "---\n",
       "\n",
       "## Publications & Thought Leadership\n",
       "22+ peer-reviewed articles and technical posts on Medium, covering:  \n",
       "- “Specialized AI Intelligence — Vertical AI Agents”  \n",
       "- “Fine-Tuning Foundational Models: A Guide to Customizing AI for Specific Needs”  \n",
       "- “Evaluating Machine Learning and Deep Learning Models”  \n",
       "- “Streaming Large Language Models: Architecture & Trade-Offs”  \n",
       "- “Bias and Variance / Overfitting and Underfitting Trade-Offs”  \n",
       "- “Data Lineage in Modern Data Management”  \n",
       "- “Discriminative vs. Generative Models: Use Cases & Comparisons”  \n",
       "- “Difference Between an ML Algorithm and an ML Model”  \n",
       "\n",
       "---\n",
       "\n",
       "## Mentoring & Leadership\n",
       "- Mentored 100+ future AI professionals via technical guidance, career coaching and project-based learning.  \n",
       "- Developed curriculum and delivered workshops on machine learning best practices, MLOps and AI ethics.  \n",
       "\n",
       "---\n",
       "\n",
       "## Community & Volunteering\n",
       "- Organized Eye Camp: screened 300+ individuals; facilitated 70+ cataract surgeries for underprivileged communities.  \n",
       "- Led Flood Relief Camp: coordinated relief materials, food, medical aid and rehabilitation for displaced families.  \n",
       "- Hosted Medical Camp at Irrukkam Island: provided free check-ups and treatments for the local fisherman community.  \n",
       "\n",
       "---\n",
       "\n",
       "## Awards & Recognitions\n",
       "- Best Mason of the Year, Pitt Macdonald Lodge No.1198, for outstanding charitable contributions.  \n",
       "- Recognition for exceptional humanitarian service in disaster-relief and community health initiatives.  \n",
       "\n",
       "---\n",
       "\n",
       "## Education\n",
       "- [Degree], [Major], [Institution], [Year]  \n",
       "- Certifications: [List relevant AI/ML certifications]\n",
       "\n",
       "---\n",
       "\n",
       "## Links & Contact\n",
       "- Portfolio & AI Projects: yourname.com/AI_hub  \n",
       "- Intellectual Portfolio: yourname.com/Intellectual_Portfolio  \n",
       "- Education Details: yourname.com/education  \n",
       "- Contact Form: yourname.com/contact  \n",
       "\n",
       "*References available upon request.*  \n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = openai.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    reasoning={\"effort\": \"medium\"},\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt }\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response.output_text)\n",
    "#response.choices[0].message.content\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51167780-3606-419c-bd63-ecb224c5f9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text has been written to output.txt\n"
     ]
    }
   ],
   "source": [
    "# Your text to write\n",
    "text = response.output_text\n",
    "\n",
    "# Open (or create) output.txt for writing, in UTF-8\n",
    "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"Text has been written to output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "520c2924-d9fe-4c49-b892-9f8e91fbca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── chunk 0 (795 chars) ──\n",
      "```markdown # PremKumar Kora   Data Scientist & AI Architect    Email: premkora@example.com • LinkedIn: https://www.linkedin.com/in/premkora/ • X: https://x.com/premkumarkora • Website: yourname.com   …\n",
      "\n",
      "── chunk 1 (418 chars) ──\n",
      "---  ## Core Competencies • Generative AI & LLMOps   • AI Architecture & System Design   • Machine Learning & Deep Learning   • Natural Language Processing (NLP)   • Prompt Engineering & Transformer M …\n",
      "\n",
      "── chunk 2 (841 chars) ──\n",
      "---  ## Professional Experience  **Senior Data Scientist & GenAI Architect (Independent Consultant)**   2000 – Present   - Architected and delivered end-to-end AI solutions across finance, healthcare, …\n",
      "\n",
      "── chunk 3 (764 chars) ──\n",
      "---  ## Patents & Intellectual Property - 2+ Patents granted in AI-driven data analytics and model optimization (details available upon request).    ---  ## Publications & Thought Leadership 22+ peer- …\n",
      "\n",
      "── chunk 4 (996 chars) ──\n",
      "---  ## Mentoring & Leadership - Mentored 100+ future AI professionals via technical guidance, career coaching and project-based learning.   - Developed curriculum and delivered workshops on machine l …\n",
      "\n",
      "── chunk 5 (384 chars) ──\n",
      "---  ## Education - [Degree], [Major], [Institution], [Year]   - Certifications: [List relevant AI/ML certifications]  ---  ## Links & Contact - Portfolio & AI Projects: yourname.com/AI_hub   - Intell …\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Read your file\n",
    "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    full_text = f.read()\n",
    "\n",
    "# 2. Wrap it in a Document (so split_documents knows what to split)\n",
    "doc = Document(page_content=full_text, metadata={\"source\": \"output.txt\"})\n",
    "\n",
    "# 3. Create and run the splitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents([doc])\n",
    "\n",
    "# `chunks` is now a list of Document objects, each with up to 1000 chars\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"── chunk {i} ({len(chunk.page_content)} chars) ──\")\n",
    "    print(chunk.page_content[:200].replace(\"\\n\", \" \"), \"…\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89ca0cd8-b6dd-4954-be77-ff78adf81903",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"scrape_website\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab57830e-a737-4ed1-811d-4b31200cf0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 6 documents\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "#If there is a old DB then delete it\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(\n",
    "        persist_directory=db_name,\n",
    "        embedding_function=embeddings\n",
    "    ).delete_collection()\n",
    "\n",
    "#create a new Vector DB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=db_name\n",
    ")\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d646b29c-d51b-4003-8e56-2b8238817955",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"o4-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "912d3931-9568-448a-8f12-8cf8b4c66e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=1, model_name=MODEL)\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "retriever = vectorstore.as_retriever()\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de5773c0-dc40-4784-92fc-ca951e6962a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prem refers to PremKumar Kora, a seasoned Data Scientist and AI Architect with over 25 years of experience in software technology and artificial intelligence. He specializes in Generative AI, Large Language Models (LLMs), NLP, predictive analytics, real-time data pipelines and cloud-based AI deployments, and has a strong track record of designing enterprise-scale AI solutions, authoring technical whitepapers, mentoring emerging AI talent and leading community humanitarian initiatives.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is Prem\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea54ec51-19fd-4a7f-a1e8-d99d61e02a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m sorry, but I don’t know where PremKumar Kora studied; the educational institution isn’t specified in the provided information.\n"
     ]
    }
   ],
   "source": [
    "query = \"Where did Prem study\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28f251d0-e434-4a32-ac9d-b68dfe564182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping that in a function\n",
    "\n",
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8f8bc-bcbb-4fb5-a4bf-3d14ee14b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35c6a319-9b22-43d9-a611-3ab05a63b9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\AppData\\Local\\Temp\\ipykernel_4136\\2165663634.py\", line 3, in process_url\n",
      "    website = Website(url)\n",
      "              ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\Documents\\Projects\\llm_engineering\\my_projects\\searchwebsite.py\", line 17, in __init__\n",
      "    response = requests.get(url, headers=headers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\sessions.py\", line 575, in request\n",
      "    prep = self.prepare_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\sessions.py\", line 484, in prepare_request\n",
      "    p.prepare(\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\models.py\", line 367, in prepare\n",
      "    self.prepare_url(url, params)\n",
      "  File \"C:\\Users\\premk\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\models.py\", line 438, in prepare_url\n",
      "    raise MissingSchema(\n",
      "requests.exceptions.MissingSchema: Invalid URL 'www.microsoft.com': No scheme supplied. Perhaps you meant https://www.microsoft.com?\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    url = gr.Textbox(label=\"Type your URL\")\n",
    "    greet_btn = gr.Button(\"Send your URL\")\n",
    "    greet_btn.click(fn=process_url, inputs=url)\n",
    "    view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)\n",
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65566f8-a3a2-4157-85cf-8d0a9378e772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3677302-0a27-4586-89ae-d3933800c1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
